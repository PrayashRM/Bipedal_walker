{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cd034d",
   "metadata": {},
   "source": [
    "# **Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import (\n",
    "    CheckpointCallback,\n",
    "    EvalCallback,\n",
    "    StopTrainingOnRewardThreshold,\n",
    "    CallbackList\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b9205",
   "metadata": {},
   "source": [
    "# **Load Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"BipedalWalker-v3\"\n",
    "\n",
    "train_env = SubprocVecEnv([\n",
    "    lambda: gym.make(environment_name, \n",
    "        hardcore = True,\n",
    "        render_mode=None)\n",
    "    for _ in range(12)\n",
    "])\n",
    "\n",
    "test_env = gym.make(environment_name, \n",
    "        hardcore = True,\n",
    "        render_mode = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75038c16",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa544833",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(r\"C:\\Users\\KIIT\\OneDrive\\Desktop\\VS CODE\\Reinforcement\\Bipedal\\saved_models\")\n",
    "checkpoint_path = Path(r\"C:\\Users\\KIIT\\OneDrive\\Desktop\\VS CODE\\Reinforcement\\Bipedal\\checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aebe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(\n",
    "    reward_threshold=500,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    test_env,\n",
    "    callback_on_new_best=stop_callback,\n",
    "    eval_freq=5000,\n",
    "    best_model_save_path=save_path,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=2048,          # every 10k steps\n",
    "    save_path=checkpoint_path,\n",
    "    name_prefix=\"lunar_ppo\",\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "callback = CallbackList([checkpoint_callback, eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    \"MlpPolicy\", \n",
    "    train_env,\n",
    "    verbose=1,\n",
    "    \n",
    "    # --- The 12-Core Optimizations ---\n",
    "    n_steps=2048,       # Collect less data before learning (12 * 1024 = 12k steps)\n",
    "    batch_size=128,     # Process larger chunks of data at once (faster on your laptop)\n",
    "    n_epochs=4,         # Don't over-train on the same data (prevents overfitting)\n",
    "    \n",
    "    # --- The Standard Good Stuff ---\n",
    "    learning_rate=3e-4,\n",
    "    gamma=0.99,        # Increased to 0.999 (LunarLander needs long-term planning)\n",
    "    gae_lambda=0.95,\n",
    "    ent_coef=0.001, \n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    policy_kwargs=dict(net_arch=[dict(pi=[256, 256], vf=[256, 256])])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=10000000, callback=callback , progress_bar= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a6670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path / \"saved_model_hardcore.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc0949",
   "metadata": {},
   "source": [
    "# **Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = r\"C:\\Users\\KIIT\\OneDrive\\Desktop\\VS CODE\\Reinforcement\\Bipedal\\ssaved_models\"  # example\n",
    "if os.path.exists(path):\n",
    "    print(\"âœ… File exists\")\n",
    "else:\n",
    "    print(\" File not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c563cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test env model load\n",
    "\n",
    "model = PPO.load(r\"C:\\Users\\KIIT\\OneDrive\\Desktop\\VS CODE\\Reinforcement\\Bipedal\\saved_models\\saved_model_normal.zip\" , env = test_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6aed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train env model load\n",
    "\n",
    "model = PPO.load(r\"C:\\Users\\KIIT\\OneDrive\\Desktop\\VS CODE\\Reinforcement\\Bipedal\\saved_models\\saved_model_hardcore.zip\" , env = train_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92619dc",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890bd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 5\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "    obs, info = test_env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    score = 0\n",
    "\n",
    "    while not (terminated or truncated):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "        score += reward\n",
    "\n",
    "    print(f\"Episode {episode} - Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env.close() \n",
    "train_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rl-venv)",
   "language": "python",
   "name": "rl-venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
